# BWE
Based on the Will Y. Zou's work on Biligual Word Embeddings, we use implicit monolingual word-level semantic equivalences by pivoting their translations in the other language as our constraints to train better bwe. 
We use two constraints, one for word-level translation probability distributions, and the other is word-level paraphrase probability distributions to learn better bilingual word embeddings. 
